{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "642e7e50",
   "metadata": {},
   "source": [
    "## TPC3 - Analisador Léxico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3ca2dc",
   "metadata": {},
   "source": [
    "### Token's de Queries SPARQL (Análise Léxica)\n",
    "- Objetivo: Construir um analisador léxico para queries SPARQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09fae7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "tokens = [\n",
    "        ('NEWLINE', r'\\n'),\n",
    "        ('SKIP', r'[ \\t]+'),\n",
    "        ('PREFIX', r'PREFIX\\b'),\n",
    "        ('SELECT', r'SELECT\\b'),\n",
    "        ('WHERE', r'WHERE\\b'),\n",
    "        ('OPTIONAL', r'OPTIONAL\\b'),\n",
    "        ('FILTER', r'FILTER\\b'),\n",
    "        ('VAR', r'\\?[a-zA-Z_][\\w]*'),     \n",
    "        ('URI', r'<[^>]*>'),              \n",
    "        ('IDENT', r':[a-zA-Z_][\\w]*'),    \n",
    "        ('INT', r'\\d+'),\n",
    "        ('STRING', r'\"[^\"]*\"'),\n",
    "        ('OP', r'[=!<>]+'),\n",
    "        ('PUNCT', r'[{}.;,]'),\n",
    "        ('ERRO', r'.')                    \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d071f384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SELECT', 'SELECT', 1, (0, 6)), ('VAR', '?a', 1, (7, 9)), ('VAR', '?b', 1, (10, 12)), ('VAR', '?c', 1, (13, 15)), ('WHERE', 'WHERE', 1, (16, 21)), ('NEWLINE', '\\n', 2, (22, 23)), ('PUNCT', '{', 2, (23, 24)), ('NEWLINE', '\\n', 3, (24, 25)), ('VAR', '?a', 3, (27, 29)), ('ERRO', 'a', 3, (30, 31)), ('IDENT', ':Pessoa', 3, (32, 39)), ('PUNCT', ';', 3, (40, 41)), ('NEWLINE', '\\n', 4, (41, 42)), ('IDENT', ':temIdade', 4, (47, 56)), ('VAR', '?b', 4, (57, 59)), ('PUNCT', ';', 4, (60, 61)), ('NEWLINE', '\\n', 5, (61, 62)), ('IDENT', ':eIrmaoDe', 5, (67, 76)), ('VAR', '?c', 5, (77, 79)), ('PUNCT', '.', 5, (80, 81)), ('NEWLINE', '\\n', 6, (81, 82)), ('PUNCT', '}', 6, (82, 83)), ('NEWLINE', '\\n', 7, (83, 84))]\n"
     ]
    }
   ],
   "source": [
    "def tokenizerSPARQL(query):\n",
    "    rec = []\n",
    "    line = 1\n",
    "    token_regex = '|'.join(f'(?P<{name}>{pattern})' for name, pattern in tokens)\n",
    "    rc = re.finditer(token_regex,query)\n",
    "    for r in rc:\n",
    "        dic = r.groupdict()\n",
    "        tipo = None\n",
    "        valor = r.group()\n",
    "        for key in dic:\n",
    "            if dic[key]:\n",
    "                tipo = key\n",
    "                break\n",
    "        if tipo == 'NEWLINE':\n",
    "            line += 1\n",
    "            rec.append((tipo, valor, line, r.span()))\n",
    "        elif tipo != 'SKIP':\n",
    "            rec.append((tipo, valor, line, r.span()))\n",
    "    \n",
    "    return rec\n",
    "\n",
    "query = \"\"\"SELECT ?a ?b ?c WHERE \n",
    "{\n",
    "  ?a a :Pessoa ;\n",
    "     :temIdade ?b ;\n",
    "     :eIrmaoDe ?c .\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(tokenizerSPARQL(query))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
